{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leilayfarsani/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import concurrent.futures\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('IATI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please make sure it is set in the .env file or update it if necessary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity/apache/select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def fetch_page(start):\n",
    "    params = {\n",
    "        'q': '(sector_code:(11250 OR 12240 OR 31110 OR 31120 OR 31130 OR 31140 OR 31150 OR 31161 OR 31162 OR 31163 OR 31164 OR 31165 OR 31166 OR 31181 OR 31182 OR 31191 OR 31192 OR 31193 OR 31194 OR 31195 OR 31210 OR 31220 OR 31261 OR 31281 OR 31282 OR 31291 OR 31310 OR 31320 OR 31381 OR 31382 OR 31391 OR 32161 OR 32162 OR 43040 OR 43071 OR 43072 OR 43073 OR 52010) OR sector_vocabulary:2 AND sector_code:(311 OR 312 OR 313)) OR (title_narrative:(\"food security\" OR \"food insecurity\") OR description_narrative:(\"food security\" OR \"food insecurity\"))',\n",
    "        #'fl': 'iati_identifier,title_narrative,description_narrative,sector_code,activity_date_iso_date,activity_date_type,recipient_country_code',\n",
    "        'fq': 'activity_date_type:2 AND activity_date_iso_date:[2021-01-01T00:00:00Z TO *]',  \n",
    "        'rows': 1000,\n",
    "        'start': start\n",
    "    }\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    \n",
    "    for attempt in range(5):  \n",
    "        try:\n",
    "            response = requests_retry_session().get(base_url, headers=headers, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            docs = response.json()['response']['docs']\n",
    "            return docs, len(docs)\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                wait = 2 ** attempt  # exponential backoff\n",
    "                print(f\"Rate limit hit. Waiting for {wait} seconds.\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                print(f\"HTTP error occurred: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    print(f\"Failed to fetch data for start={start} after 5 attempts\")\n",
    "    return [], 0\n",
    "\n",
    "def get_total_results():\n",
    "    params = {\n",
    "        'q': '(sector_code:(11250 OR 12240 OR 31110 OR 31120 OR 31130 OR 31140 OR 31150 OR 31161 OR 31162 OR 31163 OR 31164 OR 31165 OR 31166 OR 31181 OR 31182 OR 31191 OR 31192 OR 31193 OR 31194 OR 31195 OR 31210 OR 31220 OR 31261 OR 31281 OR 31282 OR 31291 OR 31310 OR 31320 OR 31381 OR 31382 OR 31391 OR 32161 OR 32162 OR 43040 OR 43071 OR 43072 OR 43073 OR 52010) OR sector_vocabulary:2 AND sector_code:(311 OR 312 OR 313)) OR (title_narrative:(\"food security\" OR \"food insecurity\") OR description_narrative:(\"food security\" OR \"food insecurity\"))',\n",
    "        'rows': 0\n",
    "    }\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    response = requests_retry_session().get(base_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['response']['numFound']\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return 0\n",
    "\n",
    "base_url = \"https://api.iatistandard.org/datastore/activity/select\"\n",
    "total_results = get_total_results() \n",
    "all_activities = []\n",
    "page_sizes = []\n",
    "\n",
    "print(f\"Total results to fetch: {total_results}\")\n",
    "\n",
    "max_empty_pages = 5  \n",
    "empty_page_count = 0\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = [executor.submit(fetch_page, i) for i in range(0, total_results, 1000)]\n",
    "    for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "        docs, size = future.result()\n",
    "        all_activities.extend(docs)\n",
    "        page_sizes.append(size)\n",
    "        print(f\"Fetched page {i+1}/{len(futures)} with {size} documents\")\n",
    "        \n",
    "        if size == 0:\n",
    "            empty_page_count += 1\n",
    "            if empty_page_count >= max_empty_pages:\n",
    "                print(f\"Stopped fetching after {max_empty_pages} consecutive empty pages\")\n",
    "                break\n",
    "        else:\n",
    "            empty_page_count = 0\n",
    "\n",
    "        time.sleep(1)  # Adding a small delay between requests\n",
    "\n",
    "print(f\"Page sizes: {page_sizes}\")\n",
    "print(f\"Sum of page sizes: {sum(page_sizes)}\")\n",
    "print(f\"Total activities fetched: {len(all_activities)}\")\n",
    "\n",
    "df_activities = pd.DataFrame(all_activities)\n",
    "\n",
    "def clean_list_field(field):\n",
    "    return field[0] if isinstance(field, list) and len(field) > 0 else field\n",
    "\n",
    "for col in ['sector_code', 'title_narrative', 'description_narrative', 'recipient_country_code']:\n",
    "    df_activities[col] = df_activities[col].apply(clean_list_field)\n",
    "\n",
    "df_activities['start_date'] = pd.to_datetime(df_activities['activity_date_iso_date'].apply(clean_list_field), errors='coerce')\n",
    "\n",
    "print(df_activities.head())\n",
    "print(f\"Shape of DataFrame: {df_activities.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Validation:\n",
    "Performing some additional checks on the data to ensure its quality and completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector_code\n",
      "31120       640\n",
      "6           622\n",
      "72010       578\n",
      "3           552\n",
      "311         403\n",
      "           ... \n",
      "31281         1\n",
      "34-01-01      1\n",
      "34-01-07      1\n",
      "11430         1\n",
      "BH            1\n",
      "Name: count, Length: 253, dtype: int64\n",
      "recipient_country_code\n",
      "AF    430\n",
      "ET    422\n",
      "SS    337\n",
      "SO    331\n",
      "YE    272\n",
      "     ... \n",
      "GZ      1\n",
      "CW      1\n",
      "CA      1\n",
      "ES      1\n",
      "NR      1\n",
      "Name: count, Length: 174, dtype: int64\n",
      "1979-01-01 00:00:00+00:00 2028-12-31 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "print(df_activities['sector_code'].value_counts())\n",
    "print(df_activities['recipient_country_code'].value_counts())\n",
    "print(df_activities['start_date'].min(), df_activities['start_date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of activities with start date before 2021-01-01: 4415\n",
      "                               iati_identifier                start_date  \\\n",
      "2                          GB-CHC-220949-P8501 2020-06-20 00:00:00+00:00   \n",
      "10                         XM-DAC-41301-663721 2020-03-01 00:00:00+00:00   \n",
      "12                     XM-DAC-3-1-264893-32579 2018-01-29 00:00:00+00:00   \n",
      "14            XI-IATI-EC_INTPA-2020-PCC-412348 2020-11-27 00:00:00+00:00   \n",
      "25  XM-OCHA-CBPF-AFG-19/3481/RA4/FSAC/UN/14864 2020-01-01 00:00:00+00:00   \n",
      "\n",
      "                               activity_date_iso_date  \n",
      "2        [2020-06-20T00:00:00Z, 2021-06-14T00:00:00Z]  \n",
      "10       [2020-03-01T00:00:00Z, 2023-02-28T00:00:00Z]  \n",
      "12  [2018-01-29T00:00:00Z, 2020-09-23T00:00:00Z, 2...  \n",
      "14  [2020-11-27T00:00:00Z, 2020-11-27T00:00:00Z, 2...  \n",
      "25  [2020-01-01T00:00:00Z, 2020-01-01T00:00:00Z, 2...  \n"
     ]
    }
   ],
   "source": [
    "early_dates = df_activities[df_activities['start_date'] < '2021-01-01']\n",
    "print(f\"Number of activities with start date before 2021-01-01: {len(early_dates)}\")\n",
    "print(early_dates[['iati_identifier', 'start_date', 'activity_date_iso_date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               iati_identifier                start_date  \\\n",
      "2                          GB-CHC-220949-P8501 2020-06-20 00:00:00+00:00   \n",
      "10                         XM-DAC-41301-663721 2020-03-01 00:00:00+00:00   \n",
      "12                     XM-DAC-3-1-264893-32579 2018-01-29 00:00:00+00:00   \n",
      "14            XI-IATI-EC_INTPA-2020-PCC-412348 2020-11-27 00:00:00+00:00   \n",
      "25  XM-OCHA-CBPF-AFG-19/3481/RA4/FSAC/UN/14864 2020-01-01 00:00:00+00:00   \n",
      "\n",
      "                                         parsed_dates  \n",
      "2        [2020-06-20T00:00:00Z, 2021-06-14T00:00:00Z]  \n",
      "10       [2020-03-01T00:00:00Z, 2023-02-28T00:00:00Z]  \n",
      "12  [2018-01-29T00:00:00Z, 2020-09-23T00:00:00Z, 2...  \n",
      "14  [2020-11-27T00:00:00Z, 2020-11-27T00:00:00Z, 2...  \n",
      "25  [2020-01-01T00:00:00Z, 2020-01-01T00:00:00Z, 2...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/bbgshr8n1m3fx_npbqvt9_w00000gn/T/ipykernel_57858/2312078001.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  early_dates['parsed_dates'] = early_dates['activity_date_iso_date'].apply(parse_dates)\n"
     ]
    }
   ],
   "source": [
    "def parse_dates(date_list):\n",
    "    return [date for date in date_list if date.startswith('2')]  \n",
    "\n",
    "early_dates['parsed_dates'] = early_dates['activity_date_iso_date'].apply(parse_dates)\n",
    "print(early_dates[['iati_identifier', 'start_date', 'parsed_dates']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 start_date             earliest_date\n",
      "0 2027-02-01 00:00:00+00:00 2022-06-21 00:00:00+00:00\n",
      "1 2022-05-08 00:00:00+00:00 2022-05-08 00:00:00+00:00\n",
      "2 2020-06-20 00:00:00+00:00 2020-06-20 00:00:00+00:00\n",
      "3 2024-02-05 00:00:00+00:00 2024-02-05 00:00:00+00:00\n",
      "4 2023-12-01 00:00:00+00:00 2023-12-01 00:00:00+00:00\n",
      "Number of activities where earliest_date != start_date: 721\n"
     ]
    }
   ],
   "source": [
    "def get_earliest_date(date_list):\n",
    "    return min(parse_dates(date_list), default=None)\n",
    "\n",
    "df_activities['earliest_date'] = df_activities['activity_date_iso_date'].apply(get_earliest_date)\n",
    "df_activities['earliest_date'] = pd.to_datetime(df_activities['earliest_date'])\n",
    "\n",
    "print(df_activities[['start_date', 'earliest_date']].head())\n",
    "print(f\"Number of activities where earliest_date != start_date: {(df_activities['earliest_date'] != df_activities['start_date']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity/XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total activities fetched: 11823\n",
      "                  iati_identifier  \\\n",
      "0                NZ-1-ACT-0103019   \n",
      "1  NL-KVK-40409352-PRJ13-108-0004   \n",
      "2             GB-CHC-220949-P8501   \n",
      "3             XM-DAC-41301-745086   \n",
      "4                 SE-0-SE-6-16450   \n",
      "\n",
      "                                     title_narrative  \\\n",
      "0                2022 Horn of Africa Food Insecurity   \n",
      "1                      2022 Food insecurity EA Niger   \n",
      "2                    Mauritania Food Insecurity 2020   \n",
      "3  Supporting Food Security Preparedness and Resi...   \n",
      "4   ACF/NRC Food and nutrition security Cabo Delgado   \n",
      "\n",
      "                               description_narrative sector_code  \\\n",
      "0  Humanitarian contributions to support the inte...        None   \n",
      "1  Niger is currently being affected by the worst...        None   \n",
      "2  Mauritania is currently facing a difficult foo...        None   \n",
      "3  To achieve higher levels of food security in t...        None   \n",
      "4  The contribution proposed will span over three...        None   \n",
      "\n",
      "  activity_date_iso_date recipient_country_code  \n",
      "0             2022-06-21                     ET  \n",
      "1             2022-05-08                     NE  \n",
      "2             2020-06-20                     MR  \n",
      "3             2024-02-05                     SO  \n",
      "4             2023-12-01                     MZ  \n"
     ]
    }
   ],
   "source": [
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def fetch_page_xml(start):\n",
    "    params = {\n",
    "        'q': '(sector_code:(11250 OR 12240 OR 31110 OR 31120 OR 31130 OR 31140 OR 31150 OR 31161 OR 31162 OR 31163 OR 31164 OR 31165 OR 31166 OR 31181 OR 31182 OR 31191 OR 31192 OR 31193 OR 31194 OR 31195 OR 31210 OR 31220 OR 31261 OR 31281 OR 31282 OR 31291 OR 31310 OR 31320 OR 31381 OR 31382 OR 31391 OR 32161 OR 32162 OR 43040 OR 43071 OR 43072 OR 43073 OR 52010) OR sector_vocabulary:2 AND sector_code:(311 OR 312 OR 313)) OR (title_narrative:(\"food security\" OR \"food insecurity\") OR description_narrative:(\"food security\" OR \"food insecurity\"))',\n",
    "        'fq': 'activity_date_iso_date:[2021-01-01T00:00:00Z TO *]',\n",
    "        'rows': 1000,\n",
    "        'start': start\n",
    "    }\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    \n",
    "    response = requests_retry_session().get(xml_base_url, headers=headers, params=params, timeout=30)\n",
    "    if response.status_code == 200:\n",
    "        return response.content  \n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\n",
    "def parse_xml_data(xml_data):\n",
    "    root = ET.fromstring(xml_data)\n",
    "    activities = []\n",
    "    for activity in root.findall('.//iati-activity'):\n",
    "        iati_id = activity.find('iati-identifier').text if activity.find('iati-identifier') is not None else None\n",
    "        title = activity.find('.//title/narrative').text if activity.find('.//title/narrative') is not None else None\n",
    "        description = activity.find('.//description/narrative').text if activity.find('.//description/narrative') is not None else None\n",
    "        \n",
    "        sector_element = activity.find('.//sector/code')\n",
    "        sector = sector_element.attrib.get('code') if sector_element is not None else None\n",
    "        \n",
    "        date_element = activity.find('.//activity-date[@type=\"2\"]')  # Type \"2\" is the actual start date\n",
    "        date = date_element.attrib.get('iso-date') if date_element is not None else None\n",
    "        \n",
    "        country_element = activity.find('.//recipient-country')\n",
    "        country = country_element.attrib.get('code') if country_element is not None else None\n",
    "        \n",
    "        activities.append({\n",
    "            'iati_identifier': iati_id,\n",
    "            'title_narrative': title,\n",
    "            'description_narrative': description,\n",
    "            'sector_code': sector,\n",
    "            'activity_date_iso_date': date,\n",
    "            'recipient_country_code': country\n",
    "        })\n",
    "    return activities\n",
    "\n",
    "def fetch_all_pages():\n",
    "    all_activities = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        xml_data = fetch_page_xml(start=start)\n",
    "        activities = parse_xml_data(xml_data)\n",
    "        if not activities:  \n",
    "            break\n",
    "        all_activities.extend(activities)\n",
    "        start += 1000  \n",
    "    return all_activities\n",
    "\n",
    "xml_base_url = \"https://api.iatistandard.org/datastore/activity/iati\"  # Updated URL for XML\n",
    "\n",
    "all_activities = fetch_all_pages()\n",
    "\n",
    "df_activity_xml = pd.DataFrame(all_activities)\n",
    "print(f\"Total activities fetched: {len(df_activity_xml)}\")\n",
    "print(df_activity_xml.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity/XML considering SDG tag code 2\n",
    "\n",
    "OR sdg tag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total activities fetched: 64729\n"
     ]
    }
   ],
   "source": [
    "def requests_retry_session(session=None, retries=3, backoff_factor=0.3, status_forcelist=(500, 502, 504)):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def fetch_page_xml(session, start):\n",
    "    params = {\n",
    "        'q': '(sector_code:(11250 OR 12240 OR 31110 OR 31120 OR 31130 OR 31140 OR 31150 OR 31161 OR 31162 OR 31163 OR 31164 OR 31165 OR 31166 OR 31181 OR 31182 OR 31191 OR 31192 OR 31193 OR 31194 OR 31195 OR 31210 OR 31220 OR 31261 OR 31281 OR 31282 OR 31291 OR 31310 OR 31320 OR 31381 OR 31382 OR 31391 OR 32161 OR 32162 OR 43040 OR 43071 OR 43072 OR 43073 OR 52010) OR sector_vocabulary:2 AND sector_code:(311 OR 312 OR 313)) OR (title_narrative:(\"food security\" OR \"food insecurity\") OR description_narrative:(\"food security\" OR \"food insecurity\")) OR tag_vocabulary:2',\n",
    "        'fq': 'activity_date_iso_date:[2021-01-01T00:00:00Z TO *]',\n",
    "        'rows': 1000,\n",
    "        'start': start\n",
    "    }\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    \n",
    "    response = session.get(xml_base_url, headers=headers, params=params, timeout=30)\n",
    "    if response.status_code == 200:\n",
    "        return response.content  \n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\n",
    "def parse_xml_data(xml_data):\n",
    "    root = ET.fromstring(xml_data)\n",
    "    activities = []\n",
    "    for activity in root.findall('.//iati-activity'):\n",
    "        iati_id = activity.find('iati-identifier').text if activity.find('iati-identifier') is not None else None\n",
    "        title = activity.find('.//title/narrative').text if activity.find('.//title/narrative') is not None else None\n",
    "        description = activity.find('.//description/narrative').text if activity.find('.//description/narrative') is not None else None\n",
    "        \n",
    "        sector_element = activity.find('.//sector/code')\n",
    "        sector = sector_element.attrib.get('code') if sector_element is not None else None\n",
    "        \n",
    "        date_element = activity.find('.//activity-date[@type=\"2\"]')  \n",
    "        date = date_element.attrib.get('iso-date') if date_element is not None else None\n",
    "        \n",
    "        country_element = activity.find('.//recipient-country')\n",
    "        country = country_element.attrib.get('code') if country_element is not None else None\n",
    "        \n",
    "        # Extract SDG tags\n",
    "        sdg_tags = activity.findall(\".//tag[@vocabulary='2']\")\n",
    "        sdg_codes = [tag.get('code') for tag in sdg_tags]\n",
    "        \n",
    "        activities.append({\n",
    "            'iati_identifier': iati_id,\n",
    "            'title_narrative': title,\n",
    "            'description_narrative': description,\n",
    "            'sector_code': sector,\n",
    "            'activity_date_iso_date': date,\n",
    "            'recipient_country_code': country,\n",
    "            'sdg_tags': sdg_codes  \n",
    "        })\n",
    "    return activities\n",
    "\n",
    "def fetch_all_records():\n",
    "    session = requests_retry_session()  \n",
    "    all_activities = []\n",
    "    start = 0\n",
    "    \n",
    "    while True:\n",
    "        xml_data = fetch_page_xml(session, start)\n",
    "        activities = parse_xml_data(xml_data)\n",
    "        if not activities:  \n",
    "            break\n",
    "        all_activities.extend(activities)\n",
    "        start += 1000  \n",
    "    \n",
    "    return all_activities\n",
    "\n",
    "\n",
    "xml_base_url = \"https://api.iatistandard.org/datastore/activity/iati\"  \n",
    "\n",
    "all_activities = fetch_all_records()\n",
    "df_activity_xml_sdg = pd.DataFrame(all_activities)\n",
    "print(f\"Total activities fetched: {len(df_activity_xml_sdg )}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sdg tag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requests_retry_session(session=None, retries=3, backoff_factor=0.3, status_forcelist=(500, 502, 504)):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def fetch_page_xml(session, start):\n",
    "    params = {\n",
    "        'q': '(sector_code:(11250 OR 12240 OR 31110 OR 31120 OR 31130 OR 31140 OR 31150 OR 31161 OR 31162 OR 31163 OR 31164 OR 31165 OR 31166 OR 31181 OR 31182 OR 31191 OR 31192 OR 31193 OR 31194 OR 31195 OR 31210 OR 31220 OR 31261 OR 31281 OR 31282 OR 31291 OR 31310 OR 31320 OR 31381 OR 31382 OR 31391 OR 32161 OR 32162 OR 43040 OR 43071 OR 43072 OR 43073 OR 52010) OR sector_vocabulary:2 AND sector_code:(311 OR 312 OR 313)) OR (title_narrative:(\"food security\" OR \"food insecurity\") OR description_narrative:(\"food security\" OR \"food insecurity\")) AND tag_vocabulary:2',\n",
    "        'fq': 'activity_date_iso_date:[2021-01-01T00:00:00Z TO *]',\n",
    "        'rows': 1000,\n",
    "        'start': start\n",
    "    }\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    \n",
    "    response = session.get(xml_base_url, headers=headers, params=params, timeout=30)\n",
    "    if response.status_code == 200:\n",
    "        return response.content  \n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "\n",
    "def parse_xml_data(xml_data):\n",
    "    root = ET.fromstring(xml_data)\n",
    "    activities = []\n",
    "    for activity in root.findall('.//iati-activity'):\n",
    "        iati_id = activity.find('iati-identifier').text if activity.find('iati-identifier') is not None else None\n",
    "        title = activity.find('.//title/narrative').text if activity.find('.//title/narrative') is not None else None\n",
    "        description = activity.find('.//description/narrative').text if activity.find('.//description/narrative') is not None else None\n",
    "        \n",
    "        sector_element = activity.find('.//sector/code')\n",
    "        sector = sector_element.attrib.get('code') if sector_element is not None else None\n",
    "        \n",
    "        date_element = activity.find('.//activity-date[@type=\"2\"]')  \n",
    "        date = date_element.attrib.get('iso-date') if date_element is not None else None\n",
    "        \n",
    "        country_element = activity.find('.//recipient-country')\n",
    "        country = country_element.attrib.get('code') if country_element is not None else None\n",
    "        \n",
    "        # Extract SDG tags\n",
    "        sdg_tags = activity.findall(\".//tag[@vocabulary='2']\")\n",
    "        sdg_codes = [tag.get('code') for tag in sdg_tags]\n",
    "        \n",
    "        activities.append({\n",
    "            'iati_identifier': iati_id,\n",
    "            'title_narrative': title,\n",
    "            'description_narrative': description,\n",
    "            'sector_code': sector,\n",
    "            'activity_date_iso_date': date,\n",
    "            'recipient_country_code': country,\n",
    "            'sdg_tags': sdg_codes  \n",
    "        })\n",
    "    return activities\n",
    "\n",
    "def fetch_all_records():\n",
    "    session = requests_retry_session()  \n",
    "    all_activities = []\n",
    "    start = 0\n",
    "    \n",
    "    while True:\n",
    "        xml_data = fetch_page_xml(session, start)\n",
    "        activities = parse_xml_data(xml_data)\n",
    "        if not activities:  \n",
    "            break\n",
    "        all_activities.extend(activities)\n",
    "        start += 1000  \n",
    "    \n",
    "    return all_activities\n",
    "\n",
    "\n",
    "xml_base_url = \"https://api.iatistandard.org/datastore/activity/iati\"  \n",
    "\n",
    "all_activities = fetch_all_records()\n",
    "df_activity_xml_and_sdg = pd.DataFrame(all_activities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions/Apache-Solr default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Transactions in XML format is not accessible from Datastore API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results to fetch: 257707\n",
      "Fetched page 1/258\n",
      "Fetched page 2/258\n",
      "Fetched page 3/258\n",
      "Fetched page 4/258\n",
      "Fetched page 5/258\n",
      "Fetched page 6/258\n",
      "Fetched page 7/258\n",
      "Fetched page 8/258\n",
      "Fetched page 9/258\n",
      "Fetched page 10/258\n",
      "Fetched page 11/258\n",
      "Fetched page 12/258\n",
      "Fetched page 13/258\n",
      "Fetched page 14/258\n",
      "Fetched page 15/258\n",
      "Fetched page 16/258\n",
      "Fetched page 17/258\n",
      "Fetched page 18/258\n",
      "Fetched page 19/258\n",
      "Fetched page 20/258\n",
      "Fetched page 21/258\n",
      "Fetched page 22/258\n",
      "Fetched page 23/258\n",
      "Fetched page 24/258\n",
      "Fetched page 25/258\n",
      "Fetched page 26/258\n",
      "Fetched page 27/258\n",
      "Fetched page 28/258\n",
      "Fetched page 29/258\n",
      "Fetched page 30/258\n",
      "Fetched page 31/258\n",
      "Fetched page 32/258\n",
      "Fetched page 33/258\n",
      "Fetched page 34/258\n",
      "Fetched page 35/258\n",
      "Fetched page 36/258\n",
      "Fetched page 37/258\n",
      "Fetched page 38/258\n",
      "Fetched page 39/258\n",
      "Fetched page 40/258\n",
      "Fetched page 41/258\n",
      "Fetched page 42/258\n",
      "Fetched page 43/258\n",
      "Fetched page 44/258\n",
      "Fetched page 45/258\n",
      "Fetched page 46/258\n",
      "Fetched page 47/258\n",
      "Fetched page 48/258\n",
      "Fetched page 49/258\n",
      "Fetched page 50/258\n",
      "Fetched page 51/258\n",
      "Fetched page 52/258\n",
      "Fetched page 53/258\n",
      "Fetched page 54/258\n",
      "Fetched page 55/258\n",
      "Fetched page 56/258\n",
      "Fetched page 57/258\n",
      "Fetched page 58/258\n",
      "Fetched page 59/258\n",
      "Fetched page 60/258\n",
      "Fetched page 61/258\n",
      "Fetched page 62/258\n",
      "Fetched page 63/258\n",
      "Fetched page 64/258\n",
      "Fetched page 65/258\n",
      "Fetched page 66/258\n",
      "Fetched page 67/258\n",
      "Fetched page 68/258\n",
      "Fetched page 69/258\n",
      "Fetched page 70/258\n",
      "Fetched page 71/258\n",
      "Fetched page 72/258\n",
      "Fetched page 73/258\n",
      "Fetched page 74/258\n",
      "Fetched page 75/258\n",
      "Fetched page 76/258\n",
      "Fetched page 77/258\n",
      "Fetched page 78/258\n",
      "Fetched page 79/258\n",
      "Fetched page 80/258\n",
      "Fetched page 81/258\n",
      "Fetched page 82/258\n",
      "Fetched page 83/258\n",
      "Fetched page 84/258\n",
      "Fetched page 85/258\n",
      "Fetched page 86/258\n",
      "Fetched page 87/258\n",
      "Fetched page 88/258\n",
      "Fetched page 89/258\n",
      "Fetched page 90/258\n",
      "Fetched page 91/258\n",
      "Fetched page 92/258\n",
      "Fetched page 93/258\n",
      "Fetched page 94/258\n",
      "Fetched page 95/258\n",
      "Fetched page 96/258\n",
      "Fetched page 97/258\n",
      "Fetched page 98/258\n",
      "Fetched page 99/258\n",
      "Fetched page 100/258\n",
      "Fetched page 101/258\n",
      "Fetched page 102/258\n",
      "Fetched page 103/258\n",
      "Fetched page 104/258\n",
      "Fetched page 105/258\n",
      "Fetched page 106/258\n",
      "Fetched page 107/258\n",
      "Fetched page 108/258\n",
      "Fetched page 109/258\n",
      "Fetched page 110/258\n",
      "Fetched page 111/258\n",
      "Fetched page 112/258\n",
      "Fetched page 113/258\n",
      "Fetched page 114/258\n",
      "Fetched page 115/258\n",
      "Fetched page 116/258\n",
      "Fetched page 117/258\n",
      "Fetched page 118/258\n",
      "Fetched page 119/258\n",
      "Fetched page 120/258\n",
      "Fetched page 121/258\n",
      "Fetched page 122/258\n",
      "Fetched page 123/258\n",
      "Fetched page 124/258\n",
      "Fetched page 125/258\n",
      "Fetched page 126/258\n",
      "Fetched page 127/258\n",
      "Fetched page 128/258\n",
      "Fetched page 129/258\n",
      "Fetched page 130/258\n",
      "Fetched page 131/258\n",
      "Fetched page 132/258\n",
      "Fetched page 133/258\n",
      "Fetched page 134/258\n",
      "Fetched page 135/258\n",
      "Fetched page 136/258\n",
      "Fetched page 137/258\n",
      "Fetched page 138/258\n",
      "Fetched page 139/258\n",
      "Fetched page 140/258\n",
      "Fetched page 141/258\n",
      "Fetched page 142/258\n",
      "Fetched page 143/258\n",
      "Fetched page 144/258\n",
      "Fetched page 145/258\n",
      "Fetched page 146/258\n",
      "Fetched page 147/258\n",
      "Fetched page 148/258\n",
      "Fetched page 149/258\n",
      "Fetched page 150/258\n",
      "Fetched page 151/258\n",
      "Fetched page 152/258\n",
      "Fetched page 153/258\n",
      "Fetched page 154/258\n",
      "Fetched page 155/258\n",
      "Fetched page 156/258\n",
      "Fetched page 157/258\n",
      "Fetched page 158/258\n",
      "Fetched page 159/258\n",
      "Fetched page 160/258\n",
      "Fetched page 161/258\n",
      "Fetched page 162/258\n",
      "Fetched page 163/258\n",
      "Fetched page 164/258\n",
      "Fetched page 165/258\n",
      "Fetched page 166/258\n",
      "Fetched page 167/258\n",
      "Fetched page 168/258\n",
      "Fetched page 169/258\n",
      "Fetched page 170/258\n",
      "Fetched page 171/258\n",
      "Fetched page 172/258\n",
      "Fetched page 173/258\n",
      "Fetched page 174/258\n",
      "Fetched page 175/258\n",
      "Fetched page 176/258\n",
      "Fetched page 177/258\n",
      "Fetched page 178/258\n",
      "Fetched page 179/258\n",
      "Fetched page 180/258\n",
      "Fetched page 181/258\n",
      "Fetched page 182/258\n",
      "Fetched page 183/258\n",
      "Fetched page 184/258\n",
      "Fetched page 185/258\n",
      "Fetched page 186/258\n",
      "Fetched page 187/258\n",
      "Fetched page 188/258\n",
      "Fetched page 189/258\n",
      "Fetched page 190/258\n",
      "Fetched page 191/258\n",
      "Fetched page 192/258\n",
      "Fetched page 193/258\n",
      "Fetched page 194/258\n",
      "Fetched page 195/258\n",
      "Fetched page 196/258\n",
      "Fetched page 197/258\n",
      "Fetched page 198/258\n",
      "Fetched page 199/258\n",
      "Fetched page 200/258\n",
      "Fetched page 201/258\n",
      "Fetched page 202/258\n",
      "Fetched page 203/258\n",
      "Fetched page 204/258\n",
      "Fetched page 205/258\n",
      "Fetched page 206/258\n",
      "Fetched page 207/258\n",
      "Fetched page 208/258\n",
      "Fetched page 209/258\n",
      "Fetched page 210/258\n",
      "Fetched page 211/258\n",
      "Fetched page 212/258\n",
      "Fetched page 213/258\n",
      "Fetched page 214/258\n",
      "Fetched page 215/258\n",
      "Fetched page 216/258\n",
      "Fetched page 217/258\n",
      "Fetched page 218/258\n",
      "Fetched page 219/258\n",
      "Fetched page 220/258\n",
      "Fetched page 221/258\n",
      "Fetched page 222/258\n",
      "Fetched page 223/258\n",
      "Fetched page 224/258\n",
      "Fetched page 225/258\n",
      "Fetched page 226/258\n",
      "Fetched page 227/258\n",
      "Fetched page 228/258\n",
      "Fetched page 229/258\n",
      "Fetched page 230/258\n",
      "Fetched page 231/258\n",
      "Fetched page 232/258\n",
      "Fetched page 233/258\n",
      "Fetched page 234/258\n",
      "Fetched page 235/258\n",
      "Fetched page 236/258\n",
      "Fetched page 237/258\n",
      "Fetched page 238/258\n",
      "Fetched page 239/258\n",
      "Fetched page 240/258\n",
      "Fetched page 241/258\n",
      "Fetched page 242/258\n",
      "Fetched page 243/258\n",
      "Fetched page 244/258\n",
      "Fetched page 245/258\n",
      "Fetched page 246/258\n",
      "Fetched page 247/258\n",
      "Fetched page 248/258\n",
      "Fetched page 249/258\n",
      "Fetched page 250/258\n",
      "Fetched page 251/258\n",
      "Fetched page 252/258\n",
      "Fetched page 253/258\n",
      "Fetched page 254/258\n",
      "Fetched page 255/258\n",
      "Fetched page 256/258\n",
      "Fetched page 257/258\n",
      "Fetched page 258/258\n"
     ]
    }
   ],
   "source": [
    "def requests_retry_session(retries=3, backoff_factor=0.3, status_forcelist=(500, 502, 504), session=None):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "def fetch_page(start):\n",
    "    params = {\n",
    "        'q': '(sector_code:(11250 OR 12240 OR 31110 OR 31120 OR 31130 OR 31140 OR 31150 OR 31161 OR 31162 OR 31163 OR 31164 OR 31165 OR 31166 OR 31181 OR 31182 OR 31191 OR 31192 OR 31193 OR 31194 OR 31195 OR 31210 OR 31220 OR 31261 OR 31281 OR 31282 OR 31291 OR 31310 OR 31320 OR 31381 OR 31382 OR 31391 OR 32161 OR 32162 OR 43040 OR 43071 OR 43072 OR 43073 OR 52010) OR sector_vocabulary:2 AND sector_code:(311 OR 312 OR 313)) OR (description_narrative:(\"food security\" OR \"food insecurity\"))',\n",
    "        'fl': 'iati_identifier,transaction_value,transaction_date_iso_date,sector_code,recipient_country_code',\n",
    "        'fq': 'transaction_transaction_date_iso_date:[2021-01-01T00:00:00Z TO *]',  \n",
    "        'rows': 1000,\n",
    "        'start': start\n",
    "    }\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    \n",
    "    for attempt in range(5):  \n",
    "        try:\n",
    "            response = requests_retry_session().get(base_url, headers=headers, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()['response']['docs']\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429:\n",
    "                wait = 2 ** attempt  # exponential backoff\n",
    "                print(f\"Rate limit hit. Waiting for {wait} seconds.\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                print(f\"HTTP error occurred: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    print(f\"Failed to fetch data for start={start} after 5 attempts\")\n",
    "    return []\n",
    "\n",
    "def get_total_results():\n",
    "    params = {\n",
    "        'q': '(sector_code:(11250 OR 12240 OR 31110 OR 31120 OR 31130 OR 31140 OR 31150 OR 31161 OR 31162 OR 31163 OR 31164 OR 31165 OR 31166 OR 31181 OR 31182 OR 31191 OR 31192 OR 31193 OR 31194 OR 31195 OR 31210 OR 31220 OR 31261 OR 31281 OR 31282 OR 31291 OR 31310 OR 31320 OR 31381 OR 31382 OR 31391 OR 32161 OR 32162 OR 43040 OR 43071 OR 43072 OR 43073 OR 52010) OR sector_vocabulary:2 AND sector_code:(311 OR 312 OR 313)) OR (description_narrative:(\"food security\" OR \"food insecurity\"))',\n",
    "        'rows': 0\n",
    "    }\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    response = requests_retry_session().get(base_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['response']['numFound']\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return 0\n",
    "\n",
    "# Updated base URL for transaction collection\n",
    "base_url = \"https://api.iatistandard.org/datastore/transaction/select\"\n",
    "\n",
    "total_results = get_total_results()\n",
    "all_transactions = []\n",
    "\n",
    "print(f\"Total results to fetch: {total_results}\")\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor: \n",
    "    futures = [executor.submit(fetch_page, i) for i in range(0, total_results, 1000)]\n",
    "    for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "        all_transactions.extend(future.result())\n",
    "        print(f\"Fetched page {i+1}/{len(futures)}\")\n",
    "        time.sleep(1) \n",
    "\n",
    "df_transactions = pd.DataFrame(all_transactions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
